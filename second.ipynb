{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words with more than 5 letters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 26\n",
      "2 427\n",
      "3 2130\n",
      "4 7186\n",
      "5 15920\n",
      "6 29874\n",
      "7 41998\n",
      "8 51627\n",
      "9 53402\n",
      "10 45872\n",
      "11 37539\n",
      "12 29125\n",
      "13 20944\n",
      "14 14149\n",
      "15 8846\n",
      "16 5182\n",
      "17 2967\n",
      "18 1471\n",
      "19 760\n",
      "20 359\n",
      "21 168\n",
      "22 74\n",
      "23 31\n",
      "24 12\n",
      "25 8\n",
      "27 3\n",
      "28 2\n",
      "29 2\n",
      "31 1\n"
     ]
    }
   ],
   "source": [
    "len2list = [list() for _ in range(32)]\n",
    "for line in open('wordle/vocabulary.txt', 'r'):\n",
    "    word = line.rstrip()\n",
    "    len2list[len(word)].append(word)\n",
    "\n",
    "for i, lst in enumerate(len2list):\n",
    "    val = len(lst)\n",
    "    if val != 0:\n",
    "        print(i, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1784613012642615"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordle.wordlenp import Wordle\n",
    "\n",
    "\n",
    "gue = Wordle._load_vocabulary('wordle/guesses.txt', astype=list)\n",
    "ans = Wordle._load_vocabulary('wordle/answers.txt', astype=list)\n",
    "\n",
    "ratio = len(ans) / len(gue)\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "for i, lst in enumerate(len2list):\n",
    "    val = len(lst)\n",
    "    if val == 0:\n",
    "        continue\n",
    "    \n",
    "    guesses = np.array(lst)\n",
    "    answers_ind = np.random.choice(len(guesses), size=ceil(len(guesses)*ratio), replace=False)\n",
    "    answers = np.sort(guesses[answers_ind])\n",
    "\n",
    "    open(f'wordle/guesses-{i}.txt', 'w').write('\\n'.join(guesses))\n",
    "    open(f'wordle/answers-{i}.txt', 'w').write('\\n'.join(answers))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "\n",
    "def load(n_letters):\n",
    "    answers = Wordle._load_vocabulary(f'wordle/answers-{n_letters}.txt', astype=list)\n",
    "    guesses = Wordle._load_vocabulary(f'wordle/guesses-{n_letters}.txt', astype=np.array)\n",
    "    wordle_list = guesses.copy().tolist()\n",
    "\n",
    "    in_answers = []\n",
    "    for i, word in enumerate(guesses):\n",
    "        loc = bisect.bisect_left(answers, word)\n",
    "        if len(answers) > loc and answers[loc] == word:\n",
    "            in_answers.append(i)\n",
    "\n",
    "    indices = np.arange(len(guesses))\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    return wordle_list, guesses, answers, indices, in_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "wordle_list = defaultdict(list)\n",
    "guesses = defaultdict(list)\n",
    "answers = defaultdict(list)\n",
    "indices = defaultdict(list)\n",
    "in_answers = defaultdict(list)\n",
    "\n",
    "answers_files = glob('wordle/answers-*.txt')\n",
    "guesses_files = glob('wordle/guesses-*.txt')\n",
    "\n",
    "for answers_file, guesses_file in zip(answers_files, guesses_files):\n",
    "    n_letters = int(re.split(r'[-\\.]', answers_file)[-2])\n",
    "    for lst, dct in zip(load(n_letters), [wordle_list, guesses, answers, indices, in_answers]):\n",
    "        dct[n_letters] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(n_guesses, overfit, indices, in_answers):\n",
    "    guesses_cur = guesses[indices[:n_guesses]]\n",
    "    \n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    for i_guess in indices[:n_guesses]:\n",
    "        if i_guess in in_answers:\n",
    "            test_indices.append(i_guess)\n",
    "        else:\n",
    "            train_indices.append(i_guess)\n",
    "\n",
    "    if overfit:\n",
    "        train_answers_cur = guesses[test_indices]\n",
    "    else:\n",
    "        train_answers_cur = guesses[train_indices]\n",
    "    \n",
    "    test_answers_cur = guesses[test_indices]\n",
    "\n",
    "    print(\n",
    "        f'guesses: {len(guesses_cur)}',\n",
    "        f'train answers: {len(train_answers_cur)}',\n",
    "        f'test answers: {len(test_answers_cur)}' + (' (overfit strategy)' if overfit else ''),\n",
    "        sep='\\n'\n",
    "    )\n",
    "\n",
    "    return train_answers_cur, test_answers_cur, guesses_cur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "from wordle.wordlenp import Wordle\n",
    "from environment.environment import Environment, StateYesNo, StateVocabulary\n",
    "from environment.action import ActionVocabulary, ActionLetters, ActionCombLetters\n",
    "from dqn.agent import Agent\n",
    "from dqn.train import Trainer\n",
    "from replay_buffer.cpprb import PrioritizedReplayBuffer, ReplayBuffer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "import torch\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe1 = ActionCombLetters(vocabulary=wordle_list, k=1).ohe_matrix\n",
    "ohe2 = ActionCombLetters(vocabulary=wordle_list, k=2).ohe_matrix\n",
    "print(ohe1.shape, ohe2.shape)\n",
    "step_rewards = {'B':0, 'Y':1, 'G':1, 'win':10, 'lose':-10, 'step':-5}\n",
    "tasks_results = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n_guesses, n_letters, overfit):\n",
    "    return Trainer.train_test_split(n_guesses, overfit, guesses[n_letters], indices[n_letters], in_answers[n_letters])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for 7 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_guesses = 2000\n",
    "n_letters = 7\n",
    "data = get_data(n_guesses, n_letters, overfit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nickname = Trainer.train_comb_letters(\n",
    "    data=data,\n",
    "    \n",
    "    n_batches=40000,\n",
    "    n_batches_warm=10,\n",
    "    \n",
    "    eps_start=1,\n",
    "    eps_end=0.01,\n",
    "    eps_decay=0.95,\n",
    "    \n",
    "    n_envs=8,\n",
    "    k=1, \n",
    "    optimize_interval=8,\n",
    "\n",
    "    agent_path=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
