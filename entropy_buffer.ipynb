{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from entropy.solver import PatternMatrix, EntropyDataCollector\n",
    "from entropy.dataset import EntropyDataset\n",
    "from wordle.wordlenp import Wordle\n",
    "from environment.environment import Environment, StateYesNo\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = Wordle._load_vocabulary('wordle/guesses.txt', astype=np.array)\n",
    "\n",
    "def make_data(n_answers, n_guesses):\n",
    "    guesses = np.random.choice(word_list, size=n_guesses, replace=False)\n",
    "    answers = np.random.choice(guesses, size=n_answers, replace=False)\n",
    "    return answers, guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abmho' 'cites' 'aware' 'blays' 'acker' 'rawin' 'anile' 'eorls' 'feers'\n",
      " 'sadza']\n"
     ]
    }
   ],
   "source": [
    "answers_10_100, guesses_10_100 = make_data(10, 100)\n",
    "print(answers_10_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lilac' 'orles' 'twirl' 'unled' 'sings' 'grind' 'sheaf' 'benny' 'slews'\n",
      " 'karst' 'rimus' 'lossy' 'joker' 'leash' 'scopa' 'viols' 'giron' 'raiks'\n",
      " 'lummy' 'renig' 'tinds' 'infos' 'logon' 'drill' 'gudes' 'ammon' 'bhoot'\n",
      " 'hurry' 'noils' 'coven' 'beryl' 'margs' 'sorbo' 'momes' 'scald' 'potch'\n",
      " 'flows' 'torus' 'prill' 'scuts' 'brith' 'tamin' 'sewar' 'joram' 'aldol'\n",
      " 'hazel' 'texes' 'sibbs' 'truth' 'spoil' 'hames' 'actin' 'maces' 'rayas'\n",
      " 'thuya' 'sugan' 'felly' 'newsy' 'bolos' 'mimeo' 'chems' 'dicty' 'liefs'\n",
      " 'scuff' 'burps' 'abyes' 'zones' 'cuspy' 'kerve' 'haith' 'amino' 'zygal'\n",
      " 'kokum' 'zambo' 'icier' 'piers' 'sambo' 'laden' 'barge' 'solei' 'mauts'\n",
      " 'groat' 'pearl' 'curse' 'jujus' 'troop' 'bilge' 'sibyl' 'gassy' 'elain'\n",
      " 'daube' 'feyly' 'duals' 'hoper' 'hains' 'beige' 'poove' 'miffy' 'lesbo'\n",
      " 'dawds']\n"
     ]
    }
   ],
   "source": [
    "answers_100_100, guesses_100_100 = make_data(100, 100)\n",
    "print(answers_100_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['toran' 'burka' 'umpie' 'brock' 'civic' 'beige' 'hoiks' 'biffo' 'nagas'\n",
      " 'sheol' 'malls' 'matzo' 'peeve' 'deshi' 'mooli' 'scaud' 'ameba' 'wadds'\n",
      " 'bayts' 'glees' 'kaput' 'bitos' 'comae' 'dosed' 'rabis' 'neats' 'tutti'\n",
      " 'stays' 'smoky' 'chase' 'resaw' 'simas' 'sowne' 'rorid' 'rebec' 'deawy'\n",
      " 'hinny' 'sores' 'cerge' 'yogas' 'fouet' 'wheel' 'sowfs' 'talus' 'yabas'\n",
      " 'topee' 'sabin' 'unbox' 'dyers' 'qophs']\n"
     ]
    }
   ],
   "source": [
    "answers_50_200, guesses_50_200 = make_data(50, 200)\n",
    "print(answers_50_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hoied' 'aarti' 'dyers' 'ingot' 'hasty' 'tices' 'tache' 'deoxy' 'sutta'\n",
      " 'score' 'fiefs' 'sling' 'ready' 'wests' 'dobes' 'tells' 'bitts' 'roper'\n",
      " 'veena' 'hewer' 'chats' 'jarta' 'ceric' 'olent' 'feare' 'bodge' 'fleer'\n",
      " 'prats' 'spiny' 'tryps' 'welts' 'march' 'jelly' 'furor' 'okapi' 'penni'\n",
      " 'curve' 'altar' 'aboon' 'salut' 'amido' 'razor' 'vouch' 'prill' 'ganev'\n",
      " 'dukka' 'noxal' 'briar' 'wills' 'trigo' 'dusts' 'meter' 'veale' 'hafiz'\n",
      " 'dosha' 'wilis' 'ohmic' 'silds' 'giust' 'blimy' 'zerda' 'mucus' 'abrin'\n",
      " 'nandu' 'larva' 'cruds' 'kaies' 'hussy' 'dolce' 'birch' 'madam' 'chase'\n",
      " 'onely' 'molys' 'scape' 'sauce' 'amate' 'mohur' 'vagal' 'royne' 'spics'\n",
      " 'azuki' 'acres' 'shops' 'sicks' 'sunup' 'cosey' 'louse' 'aweel' 'skosh'\n",
      " 'twoer' 'loves' 'wents' 'reest' 'winna' 'rosed' 'mbira' 'rangy' 'omega'\n",
      " 'moira' 'typey' 'romal' 'bachs' 'floss' 'scath' 'roast' 'moola' 'moles'\n",
      " 'witch' 'rabbi' 'chest' 'aulos' 'yokes' 'aspen' 'sepic' 'lirot' 'lemon'\n",
      " 'musts' 'drouk' 'kudzu' 'yacka' 'sonny' 'hived' 'letch' 'zuzim' 'diota'\n",
      " 'sared' 'diker' 'ripps' 'dinge' 'cides' 'grimy' 'flexo' 'wider' 'thaws'\n",
      " 'djins' 'twirp' 'gulps' 'sated' 'tommy' 'amice' 'anode' 'strut' 'empty'\n",
      " 'maqui' 'etnas' 'saids' 'schul' 'surds' 'spoil' 'stele' 'caulk' 'muted'\n",
      " 'whist' 'teuch' 'allow' 'calls' 'agism' 'nifes' 'phons' 'horks' 'sucky'\n",
      " 'booms' 'cling' 'sikas' 'repay' 'neive' 'drops' 'mavin' 'cobbs' 'trefa'\n",
      " 'benny' 'nutsy' 'manul' 'anomy' 'adhan' 'muons' 'chelp' 'fagin' 'piper'\n",
      " 'dynel' 'cotes' 'dangs' 'weber' 'hooey' 'texas' 'baize' 'plumy' 'lurve'\n",
      " 'joint' 'fusts' 'repot' 'cloze' 'ditsy' 'stirp' 'scars' 'ribby' 'sluts'\n",
      " 'thema' 'flume' 'noahs' 'linns' 'cymol' 'creme' 'shirk' 'shakt' 'segol'\n",
      " 'dreks' 'mamma' 'dyads' 'broil' 'roupy' 'leeze' 'gears' 'atoks' 'maths'\n",
      " 'bindi' 'coden' 'coram' 'cardy' 'lupus' 'etats' 'anoas' 'south' 'hotel'\n",
      " 'golly' 'razoo' 'pulse' 'smews' 'capex' 'bonds' 'rewet' 'kines' 'stool'\n",
      " 'marid' 'bloat' 'trass' 'rases' 'diddy' 'fetas' 'gadso' 'gauje' 'heids'\n",
      " 'pesky' 'ponga' 'yogic' 'purin' 'sower' 'doats' 'kybos' 'azoth' 'genty'\n",
      " 'unled' 'alway' 'camus' 'laith' 'roost' 'meows' 'aking' 'skeer' 'hiois'\n",
      " 'dowle' 'ragas' 'rucks' 'thuds' 'welch' 'lurex' 'uplay' 'bedim' 'incle'\n",
      " 'manis' 'tenon' 'dated' 'kamas' 'bydes' 'treyf' 'roses' 'kotow' 'quasi'\n",
      " 'apode' 'walla' 'games' 'uncoy' 'angel' 'primy' 'parly' 'izzat' 'dukas'\n",
      " 'lands' 'saunt' 'coppy' 'trest' 'ticca' 'waite' 'verge' 'jenny' 'pshaw'\n",
      " 'linga' 'afore' 'yowza']\n"
     ]
    }
   ],
   "source": [
    "answers_300_300, guesses_300_300 = make_data(300, 300)\n",
    "print(answers_300_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fumed' 'rival' 'zizit' 'wests' 'scrog' 'gryce' 'seils' 'sugar' 'glims'\n",
      " 'pharm' 'pyets' 'kilts' 'bings' 'emyde' 'duads' 'shahs' 'spaza' 'spore'\n",
      " 'redub' 'sidas' 'choco' 'woofs' 'sukuk' 'spumy' 'mirex' 'sluse' 'tween'\n",
      " 'nodus' 'wands' 'unled' 'rates' 'toxin' 'lotes' 'wacko' 'ariot' 'baisa'\n",
      " 'sways' 'roads' 'poked' 'popsy' 'gonif' 'vutty' 'bicep' 'parky' 'braid'\n",
      " 'ports' 'spyal' 'match' 'spook' 'scowp' 'sdein' 'lovie' 'torii' 'souks'\n",
      " 'vibey' 'genny' 'clues' 'decaf' 'diced' 'delay' 'mirly' 'flogs' 'lotos'\n",
      " 'whine' 'seems' 'jerry' 'scram' 'gosse' 'roped' 'pipis' 'spank' 'seder'\n",
      " 'doorn' 'evict' 'buteo' 'ponks' 'miffy' 'potin' 'rathe' 'papaw' 'local'\n",
      " 'tolus' 'apode' 'jouks' 'decad' 'temes' 'wafts' 'liter' 'kagos' 'piste'\n",
      " 'ogmic' 'fyles' 'brace' 'adage' 'hepar' 'bales' 'molal' 'eject' 'seles'\n",
      " 'commy']\n"
     ]
    }
   ],
   "source": [
    "answers_100_2000, guesses_100_2000 = make_data(100, 2000)\n",
    "print(answers_100_2000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Симуляция игр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(guesses, answers, nickname):\n",
    "    \n",
    "    pattern_matrix = PatternMatrix()\n",
    "    pattern_matrix.generate(guesses, answers)\n",
    "\n",
    "    env = Environment(\n",
    "        rewards={'B':0, 'Y':1, 'G':1, 'win':10, 'lose':-10, 'step':-5},\n",
    "        wordle=Wordle(vocabulary=guesses, answers=answers),\n",
    "        state_instance=StateYesNo(),\n",
    "    )\n",
    "\n",
    "    entropy_data = EntropyDataCollector(\n",
    "        env=env,\n",
    "        pattern_matrix=pattern_matrix\n",
    "    )\n",
    "\n",
    "    entropy_data.generate(nickname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score: 7.10\tMean Steps: 2.0000\tWin Rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "simulate(guesses_10_100, answers_10_100, '10-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score: 4.25\tMean Steps: 2.6700\tWin Rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "simulate(guesses_100_100, answers_100_100, '100-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score: 3.02\tMean Steps: 3.0133\tWin Rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "simulate(guesses_300_300, answers_300_300, '300-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score: 3.86\tMean Steps: 2.7400\tWin Rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "simulate(guesses_100_2000, answers_100_2000, '100-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = Wordle._load_vocabulary('wordle/guesses.txt', astype=np.array)\n",
    "answers = Wordle._load_vocabulary('wordle/answers.txt', astype=np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ilya/repos/wordle-rl/entropy_buffer.ipynb Cell 17\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m simulate(guesses, answers, \u001b[39m'\u001b[39;49m\u001b[39mfull\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/home/ilya/repos/wordle-rl/entropy_buffer.ipynb Cell 17\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m env \u001b[39m=\u001b[39m Environment(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     rewards\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mG\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwin\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m10\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlose\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m},\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     wordle\u001b[39m=\u001b[39mWordle(vocabulary\u001b[39m=\u001b[39mguesses, answers\u001b[39m=\u001b[39manswers),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     state_instance\u001b[39m=\u001b[39mStateYesNo(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m entropy_data \u001b[39m=\u001b[39m EntropyDataCollector(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     env\u001b[39m=\u001b[39menv,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     pattern_matrix\u001b[39m=\u001b[39mpattern_matrix\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ilya/repos/wordle-rl/entropy_buffer.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m entropy_data\u001b[39m.\u001b[39;49mgenerate(nickname)\n",
      "File \u001b[0;32m~/repos/wordle-rl/entropy/solver.py:253\u001b[0m, in \u001b[0;36mEntropyDataCollector.generate\u001b[0;34m(self, nickname)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39m# play games with all test words\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39mfor\u001b[39;00m i_episode \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_episodes\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 253\u001b[0m     score, steps, win \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_play_episode(i_episode, output, res)\n\u001b[1;32m    254\u001b[0m     all_scores\u001b[39m.\u001b[39mappend(score)\n\u001b[1;32m    255\u001b[0m     all_steps\u001b[39m.\u001b[39mappend(steps)\n",
      "File \u001b[0;32m~/repos/wordle-rl/entropy/solver.py:205\u001b[0m, in \u001b[0;36mEntropyDataCollector._play_episode\u001b[0;34m(self, i, output, buffer)\u001b[0m\n\u001b[1;32m    202\u001b[0m     guess \u001b[39m=\u001b[39m answers[\u001b[39m0\u001b[39m]\n\u001b[1;32m    203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[39m# make a guess that has max entropy\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     ents \u001b[39m=\u001b[39m entropies(guesses, answers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpattern_matrix)\n\u001b[1;32m    206\u001b[0m     guess \u001b[39m=\u001b[39m guesses[ents\u001b[39m.\u001b[39margmax()]\n\u001b[1;32m    208\u001b[0m     \u001b[39m# this implements Wordle logic\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/wordle-rl/entropy/solver.py:174\u001b[0m, in \u001b[0;36mentropies\u001b[0;34m(guesses, answers, pattern_matrix)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mentropies\u001b[39m(guesses, answers, pattern_matrix):\n\u001b[1;32m    166\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m    This routine will normalize distributions if they don't sum to 1.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39m    If weights are not specified 1.0 is used.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39m        entropies: np.ndarray of shape (len(guesses),)\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     distributions \u001b[39m=\u001b[39m pattern_distributions(guesses, answers, pattern_matrix)\n\u001b[1;32m    175\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(distributions\u001b[39m.\u001b[39mshape) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m entropy(distributions, base\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/repos/wordle-rl/entropy/solver.py:161\u001b[0m, in \u001b[0;36mpattern_distributions\u001b[0;34m(guesses, answers, pattern_matrix)\u001b[0m\n\u001b[1;32m    158\u001b[0m     tmp\u001b[39m.\u001b[39mappend(pattern_matrix\u001b[39m.\u001b[39mguess_to_ind[word])\n\u001b[1;32m    160\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: pattern_matrix\u001b[39m.\u001b[39manswer_to_ind[x], answers):\n\u001b[0;32m--> 161\u001b[0m     res[\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(guesses)), pattern_matrix[tmp, i]] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m res \u001b[39m/\u001b[39m res\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "simulate(guesses, answers, 'full')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn.model import QNetwork\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model = QNetwork(\n",
    "        state_size=StateYesNo().size,\n",
    "        action_size=1\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
